[{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696363102,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://ckids-datafest.github.io/2023-fall-nn-forgetting/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/2023-fall-nn-forgetting/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"This page contains key sections of the Final Report for the project focused on the data science methodology used to approach the problem. It should be no more than 3 pages long. It should be done after or in combination with the Requirements document. It should have an initial release after no more than eight weeks into the project, and can serve as an interim project report. It can be refined as the project progresses and the problem is better understood.\nData Quality Describe any steps that were used to address any issues concerning the quality of the data. This may include collecting data quality metrics, discarding subsets of the data, or applying specific techniques for handling missing values, dealing with outliers, etc.\nData Preprocessing Describe the steps taken to preprocess the raw data to prepare it for analysis. This may include data transformations to convert to a required format, feature engineering operations, encoding features as binary, etc.\nExploratory Data Analysis (EDA) Discuss any techniques employed to gain insights into the data. This could include data visualizations, generating summary statistics, initial analysis, and other exploratory techniques used to understand the data distributions, features, and helpful patterns.\nModel Development Describe the algorithms, methodology, and architectures used to generate models. Discuss how models were generated, seeded, and improved. Show the libraries and frameworks used for model development, as well as the rationale behind those choices.\nModel Evaluation Discuss the evaluation metrics used to assess model performance, and justify those choices based on the problem that the project is addressing. Describe the evaluation techniques used, such as cross-validation, and how undesirable model behaviors, such as overfitting, were avoided.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696363102,"objectID":"3e050718825977bdecb55c075afa314a","permalink":"https://ckids-datafest.github.io/2023-fall-nn-forgetting/approach/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-nn-forgetting/approach/","section":"","summary":"Data science methodology used to address the problem, including data preprocessing steps, exploratory data analysis, feature engineering techniques, machine learning models, and evaluation metrics.","tags":null,"title":"Approach","type":"page"},{"authors":null,"categories":null,"content":"Introduction Since we were dealing with a very fundamental issue, we picked a very simple dataset to first reproduce the issue and later research ways on how to fix it.\nData Overview and Examples We used the Fashion mnist dataset for this problem statement. We also tried to run the system with Cifar-10 dataset. Despite being fairly simplistic in nature, these datasets can be engineered to get a non-IID and IID fractions. Very simply put, IID stands for data that comes from independent, identically distributed dataset. Non-IID is the exact opposite of that. This dataset doesn’t share a common distribution. In real life Machine Learning problem statement, the dataset is predominantly Non-IID and also we generally don’t know the true underlying distribution of the data. So it is very important that we truly understand this problem and make attempts to solve it. IID : Non-IID:\nThis is simply how we simulate IID and Non-IID dataset from Fashion Mnist data. ","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701833034,"objectID":"be566fdb6f0fa08cfea50d77a89a6b5a","permalink":"https://ckids-datafest.github.io/2023-fall-nn-forgetting/data/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-nn-forgetting/data/","section":"","summary":"Data Assessment Document that gives an overview of the data used for the project.","tags":null,"title":"Data Assessment","type":"page"},{"authors":null,"categories":null,"content":"Introduction Federated Learning originates from the rising concerns about data privacy and the constraints of conventional centralized machine learning approaches. It emerged as a solution to safeguard user privacy while leveraging the wealth of knowledge found in dispersed data sources.\nIndustries increasingly embraced this concept upon realizing its potential for cooperative learning within the bounds of data privacy regulations. Its rapid evolution owes much to progress in encryption methods, communication protocols, and decentralized optimization algorithms. Presently, Federated Learning represents an encouraging framework that facilitates collaboration among diverse entities, prioritizing the protection of confidential user information and driving advancements in privacy-focused machine learning.\nMotivation The overall motivation for the project is to address and fix the issue of client drift in case of non-IID distributions being used to train different clients.\nProblem for the Semester For the semester, we had two simple goals : To establish a working federated learning network - a problem statement rooted in Engineering and the second one was to visualized how the clients drifted - to answer the question : how does one quantify this drift?\nState of the Art We initially sought to reproduce and test the network proposed in FedSiM. We shall report the findings in the subsequent sections. We were also fascinated by the amazing math based proof for fixing client drifts in SCAFFOLD: Stochastic Controlled Averaging for Federated Learning and wanted to implement the paper’s proposed system.\nDesign and Approach Though initially framed as an engineering problem, at its essence, this constituted a research project aimed at exploring and executing various academic papers to evaluate their effectiveness. Consequently, we implemented two noteworthy papers over the semester to analyze and observe their outcomes. (1) For FedSiM paper : We built a network of Convolution Neural Networks(clients) and a Community model. Like it is proposed in the paper, we manipulated each neuron in every layer of the network with a small value to observe its overall impact on the output of the network. (2) For the SCAFFOLD paper : We built a Federated network of convolutional neural networks and a community model. Each model was equipped with a client control variate as proposed in the paper to account and adjust for the client drift.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701918649,"objectID":"b7c3446bb0d5d7e8a477294017361379","permalink":"https://ckids-datafest.github.io/2023-fall-nn-forgetting/problem-statement/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-nn-forgetting/problem-statement/","section":"","summary":"Problem and Requirements document that will drive the work to be done in the project","tags":null,"title":"Problem and Requirements","type":"page"},{"authors":null,"categories":null,"content":"This page contains key sections of the Final Report for the project focused on results to date. It should be no more than 2 pages long. An initial draft can be created at any point during the project, and can be refined as the project progresses.\nSystem and Model Performance Show the performance of the best system and model(s) developed, showing clearly the performance metrics and improvements over the baseline system as appropriate. Create visualizations that show clearly these results.\nDiscussion of Findings Offer a discussion of the main findings using the system developed. Put the results in the context of the original problem statement and the questions that were posed.\nDiscuss any unexpected results, and potential explanations.\nEnumerate (ideally in bullets) the most important findings, and their impact on your project goals.\nLimitations and Future Work Discuss any limitations of the work to date, how these limitations could be addressed in future work. Discuss what lines of work are most promising given the understanding of the problem and the data gained throughout the project.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696363102,"objectID":"c29e41198fe1dc5c85e66dbe4f2d7737","permalink":"https://ckids-datafest.github.io/2023-fall-nn-forgetting/results/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-nn-forgetting/results/","section":"","summary":"The main results of the work done to date","tags":null,"title":"Results","type":"page"}]